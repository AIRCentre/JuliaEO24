{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../figures/JuliaEO2024_banner.png\" alt=\"Descriptive Image Text\" style=\"border:1px solid black\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "The objectives of this workshop are the following:\n",
    "\n",
    "\n",
    "- **Understand SAR Imagery**: Gain an understanding of SAR imagery, its properties, and why it's advantageous for maritime surveillance.\n",
    "- **Data Handling**: Learn how to acquire and prepare SAR data from the Sentinel-1 satellite.\n",
    "- **Apply Machine Learning**: Explore machine learning techniques, from basic classification to object detection models.\n",
    "- **Real-World Application**: Gain practical skills in applying these models to real-world SAR data for effective maritime surveillance.\n",
    "\n",
    "\n",
    "\n",
    "____________________\n",
    "\n",
    "\n",
    "\n",
    "## Notebooks\n",
    "\n",
    "- 1: [Sentinel-1 data acquisition](1_Data_acqusition.ipynb)\n",
    "- 2: [Ship binary classification](2_Ship_binary_classification.ipynb)\n",
    "- 3: [Two stage ship detection](3_two_stage_ship_detector.ipynb)\n",
    "- 4: [One stage ship detection](4_One_stage_ship_detector.ipynb)\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"../figures/overview_notebooks.png\" alt=\"Descriptive Image Text\" width=\"800\" />\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Two stage ship detection\n",
    " <a class=\"anchor\" id=\"toc\"></a>\n",
    "-  [Objectives](#Objectives)\n",
    "-  [Two stage ship detector intro](#one_stage_object)\n",
    "-  [Include modules](#init)\n",
    "-  [Data](#data)\n",
    "-  [Stage 1](#Transformations)\n",
    "-  [Stage 2](#inferrence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Objectives\n",
    " <a class=\"anchor\" id=\"Objectives\"></a>\n",
    " Back to [Table of Content](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this notebook are the following:\n",
    "1. Combine the ship classifier from [Ship binary classification](2_Ship_binary_classification.ipynb) with an object detector (here CA-CFAR)\n",
    "2. Apply the two stage ship detector to a Sentinel-1 image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Two stage ship detector intro\n",
    "Back to [Table of Content](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The two-stage ship detection workflow represents a traditional approach where the first stage is dedicated to object detection, here performed using Constant False Alarm Rate (CA-CFAR), and the second stage involves binary classification using a convolutional neural network (CNN).\n",
    "\n",
    " *1. First Stage: CA-CFAR Object Detection*\n",
    "\n",
    "- **CA-CFAR Technique**: This radar processing technique is utilized to detect objects against a varying background noise level. It adapts the detection threshold automatically, aiming to maintain a constant false alarm rate regardless of the background noise.\n",
    "- **Initial Detection**: The algorithm scans through the radar imagery to flag potential areas of interest where objects may be present.\n",
    "\n",
    "This stage could be changed to a more advanced CA-CFAR(using convolutions), or a 2d wavelet transform etc.\n",
    "\n",
    "*2. Second Stage: Binary Classification*\n",
    "\n",
    "- **Binary CNN Classifier**: The flagged areas from the CA-CFAR stage are further examined by a CNN that classifies the region as containing a ship ('ship') or not ('no ship').\n",
    "- **Feature Extraction and Decision Making**: The CNN learns to extract features that are indicative of ships and makes a final decision on the presence of a ship in each candidate region identified by the CA-CFAR.\n",
    "\n",
    "*Workflow Limitations*\n",
    "\n",
    "While this method has been historically significant, it is not without drawbacks, especially when compared to modern one-stage detection methods:\n",
    "\n",
    "- **Speed and Efficiency**: The sequential nature of this workflow limits its efficiency, making it less suitable for real-time applications compared to one-stage detectors that perform both localization and classification simultaneously.\n",
    "- **Complexity**: Managing and optimizing two separate stages adds to the overall complexity, requiring extensive fine-tuning to achieve optimal performance.\n",
    "- **Adaptability**: The binary classifier's effectiveness can be highly contingent on the diversity and representativeness of the training data. It may incorrectly classify new types of objects with high confidence, leading to misidentification.\n",
    "- **Resource Intensity**: The need for considerable computational power to run both stages can be more demanding than a unified one-stage model.\n",
    "\n",
    "\n",
    "Advancements in deep learning have ushered in more sophisticated methods, such as one-stage object detectors, which offer a more streamlined, accurate, and efficient solution for ship detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on this specific dataset and two-stage ship detector see, e.g., \n",
    "\n",
    "Jafari, Z.; Karami, E.; Taylor, R.; Bobby, P. Enhanced Ship/Iceberg Classification in SAR Images Using Feature Extraction and the Fusion of Machine Learning Algorithms. Remote Sens. 2023, 15, 5202. https://doi.org/10.3390/rs15215202 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Disclaimer:</b> \n",
    "The two stage ship detector used in this notebook is a simple version of the more advanced ones, see e.g https://doi.org/10.3390/rs15215202  or https://www.nature.com/articles/s41586-023-06825-8.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Init <a class=\"anchor\" id=\"init\">​</a>\n",
    "Back to [Table of Content](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(url=\"https://github.com/aalling93/VesselDetection.jl\")\n",
    "#Pkg.add([\"Makie\",\"GLMakie\",\"Plots\"])\n",
    "using VesselDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg, Makie, GLMakie, Plots\n",
    "GLMakie.activate!(inline=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data \n",
    "<a class=\"anchor\" id=\"data\">​</a>\n",
    "Back to [Table of Content](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Ship binary classification](2_Ship_binary_classification.ipynb), we trained a CNN to classify individual image chips as containing a ship or not. In this notebook, we will use the same model to classify regions of interest (ROIs) identified by the CA-CFAR algorithm as containing a ship or not. Specifically, we detect ships in a new Sentinel-1 SAR image downloaded from [Sentinel-1 data acquisition](1_Data_acqusition.ipynb).  The Sentinel-1 image can be loaded using the Sentinel1GRD function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "test_img = VesselDetection.Sensors.Sentinel1.Sentinel1GRD(safe_path);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Task: </b>\n",
    "\n",
    "1. Load the Sentinel-1 IW GRD image downloaded from Notebook 1 : S1A_IW_GRDH_1SDV_20220612T173329_20220612T173354_043633_05359A_EA25 (or download another image)\n",
    "\n",
    "2. Confirm the image is loaded correctly by plotting the image and the metadata, e.g., by checking the image mode and elevation angle\n",
    "    - println(test_img.metadata.header.swath)\n",
    "    - println(\"Elevation angles: $(test_img.metadata.geolocation.elevation_angle[1:10])\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the image:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_folder = \"../data/S1A_IW_GRDH_1SDV_20220612T173329_20220612T173354_043633_05359A_EA25_test.SAFE\";\n",
    "test_img = VesselDetection.Sensors.Sentinel1.Sentinel1GRD(safe_folder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = Figure(size = (600, 400))\n",
    "ax = Axis(fig[1, 1], title = \"Image\")\n",
    "im = image!(ax, test_img.data[1][:,:], colormap = :greys)\n",
    "Colorbar(fig[1, 2], im, label = \"Value\", vertical = true)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_matrix = vec(test_img.data[1])\n",
    "histogram(flat_matrix, bins=50, xlabel=\"Value\", ylabel=\"Frequency\", title=\"Histogram of image values\", legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  need to apply the same preprocessing steps to the new image as we did to the training data. Transformations can be applied using the TransformCompose function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_transform = VesselDetection.Ship_detector.Transformation.TransformCompose([\n",
    "    VesselDetection.Ship_detector.Transformation.absolute,\n",
    "    x -> VesselDetection.Ship_detector.Transformation.clip_to_valid_range(x, amin=1, amax=65535),\n",
    "    VesselDetection.Ship_detector.Transformation.to_linear,\n",
    "    VesselDetection.Ship_detector.Transformation.to_db,\n",
    "    x -> VesselDetection.Ship_detector.Transformation.to_channels(x, [1, 2]),\n",
    "    VesselDetection.Ship_detector.Transformation.to_float32,\n",
    "    \n",
    "]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img2 = s1_transform(test_img.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = Figure(size = (600, 400))\n",
    "ax = Axis(fig[1, 1], title = \"Image with applied transforms\")\n",
    "im = image!(ax, test_img2[1,:,:], colormap = :greys, )\n",
    "Colorbar(fig[1, 2], im, label = \"Value\", vertical = true)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_matrix = vec(test_img2[1,:,:])\n",
    "histogram(flat_matrix, bins=50, xlabel=\"Value\", ylabel=\"Frequency\", title=\"Histogram of image values\", legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not applying furhter normalization, e.g., normalizing to the range [0,1], since this was applied for each subset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 1: CA-CFAR\n",
    "Back to [Table of Content](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first stage of the workflow, we will detect objects. This stage does not furhter classify the objects. Sometimes, it is assumed that all objects detected on the oceans are ships. However, as we saw in the presentation, this is not always the case.\n",
    "\n",
    "Many different algorithms can be used to detect objects. Here, we will use a simple CA-CFAR algorithm. The algorithm is implemented in the function `VesselDetection.Detection.CACFAR`. However, you are also welcome to test some of `Images`'s own object detection methods.\n",
    "\n",
    "for more information on CFAR see, e.g., [CFAR](../Theory/cfar.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paramters for the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_window = 41; #pixels in image geometry\n",
    "guard_window = 31; #pixels in image geometry\n",
    "probability_for_alarms = 10^(-12);\n",
    "target_size = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"standard\" CFAR. We are only applying it to one band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ca_cfar = VesselDetection.Ship_detector.cell_averaging_constant_false_alarm_rate(test_img2[1,:,:],\n",
    "                                                                                    background_window ÷ 2,\n",
    "                                                                                    guard_window ÷ 2,\n",
    "                                                                                    target_size, \n",
    "                                                                                    probability_for_alarms);\n",
    "image_ca_cfar = VesselDetection.Ship_detector.binarize_array(image_ca_cfar);\n",
    "objects1 = VesselDetection.Ship_detector.object_locations(image_ca_cfar);\n",
    "print(\"Objects: \",size(objects1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a CFAR that also applied morphology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cp_cfar = VesselDetection.Ship_detector.constant_false_alarm_rate_with_convolution_and_pooling(test_img2[1,:,:],\n",
    "                                                                                    background_window ÷ 2,\n",
    "                                                                                    guard_window ÷ 2,\n",
    "                                                                                    probability_for_alarms);\n",
    "image_cp_cfar = VesselDetection.Ship_detector.binarize_array(image_cp_cfar);         \n",
    "objects = VesselDetection.Ship_detector.object_locations(image_cp_cfar);\n",
    "print(\"Objects: \",size(objects))                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = Figure(size = (600, 300))\n",
    "ax = Axis(fig[1, 1], title = \"Detector 1\\nObjects: $(size(objects))\")\n",
    "im = image!(ax, image_cp_cfar, colormap = :greys)\n",
    "\n",
    "ax = Axis(fig[1, 2], title = \"Detector 2\\nObjects: $(size(objects1))\")\n",
    "im = image!(ax, image_ca_cfar, colormap = :greys)\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the classic CA-CFAR (Detector 2) finds very many objects while detector 1 only finds 13. \n",
    "In this specific case, it is clear that the classic CA-CFAR is not a good choice. However, this shows the issues in optimizing the CFAR, because Detector 1 might not detect small vessels, such as fishing vessels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Task: </b>\n",
    "\n",
    "1. Play around with the paramters of the CFAR, and see how much the results change. -> This illustrated the difficulty in optimizing the CFAR.\n",
    "\n",
    "2. Look at some of the results from both detectors. Ensure that ships indeed are detected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ix = 2\n",
    "fig = Figure(size = (600, 400))\n",
    "ax = Axis(fig[1, 1], title = \"Detected object\")\n",
    "im = image!(ax, test_img2[1,max(objects[ix][1]-37,1):objects[ix][1]+37,max(objects[ix][2]-37,1):objects[ix][2]+37], colormap = :greys)\n",
    "Colorbar(fig[1, 2], im, label = \"Value\", vertical = true)\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stage 2: Binary classification\n",
    "Back to [Table of Content](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second step, we will use the object detector we trained in [Ship binary classification](2_Ship_binary_classification.ipynb) to classify the objects detected in the first step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the path to your model.\n",
    "model = VesselDetection.Ship_detector.Model.Binary_model.load_model(\"../data/Model/classification_model.bson\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 1\n",
    "target_1 = test_img2[:,objects[ix][1]-37:objects[ix][1]+37,objects[ix][2]-37:objects[ix][2]+37];\n",
    "println(size(target_1))\n",
    "image(target_1[1,:,:], colormap = :greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images need to have the shape 75x75x2xB and be normalized to the range 0-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing order of dims\n",
    "target_1 = permutedims(target_1, [2, 3, 1]);\n",
    "# adding the batch dimension (could also just concatanate the many subsets on the 4th dim.)\n",
    "target_1 = reshape(target_1, (75, 75, 2,1));\n",
    "# noamlize the bands\n",
    "target_1 = VesselDetection.Ship_detector.Model.normalize_bands(target_1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not classify the subset. \n",
    "\n",
    "``probability > threshold --> iceberg``\n",
    "\n",
    "``probability < threshold --> ship``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(VesselDetection.Ship_detector.Model.Binary_model.classify(input =target_1, model = model,threshold = 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Task: </b>\n",
    "\n",
    "1. See what the estimates are for the other objects.\n",
    "\n",
    "2. Now try to classify a subset without any object. You will properbly get a log score, i.e., a ship. Why is this the case?\n",
    "\n",
    "3. Think about the drawbacks of this approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
